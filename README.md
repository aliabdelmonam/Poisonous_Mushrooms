# Machine Learning Classification Project

## Overview

This repository contains a machine learning classification project demonstrating the use of XGBoost, hyperparameter tuning with Bayesian optimization, and the implementation of scikit-learn pipelines. The project also includes data preprocessing steps such as Ordinal encoding and handling null values with `SimpleImputer`.

## Project Components

### 1. **Data Preprocessing**
- **Ordinal Encoding**: To handle Categorical features.
- **SimpleImputer**: Handles missing values by imputing them with the mean (for numerical features) or the most frequent value (for categorical features).
- **IsolationForest**: For detecting outlier

### 2. **Machine Learning Models**
- **XGBoost**: An efficient and scalable gradient boosting framework.

### 3. **Hyperparameter Tuning**
- **Bayesian Optimization**: Used for optimizing hyperparameters to improve model performance.

### 4. **Pipeline Integration**
- **scikit-learn Pipelines**: Combines preprocessing and model training steps into a single pipeline to streamline workflows and ensure reproducibility.

### 5. **Accuracy**
-  .96 on test dataset
## Link Notebook
-  [Kaggle Notebook](https://www.kaggle.com/code/aliabdelmenam/poisonous-mushroomsv3)
-  [Kaggle competition](https://www.kaggle.com/competitions/playground-series-s4e8)
